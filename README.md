# Klasyfikacja ObrazÃ³w MNIST i PneumoniaMNIST przy UÅ¼yciu Sieci Neuronowych

**Autor:** Marcin Przybylski
**Data:** 29 kwietnia 2025

## Opis Projektu

Niniejszy projekt koncentruje siÄ™ na zastosowaniu gÅ‚Ä™bokiego uczenia do problemÃ³w klasyfikacji obrazÃ³w. Analizie poddano dwa zbiory danych: MNIST, zawierajÄ…cy rÄ™cznie pisane cyfry, oraz PneumoniaMNIST, skÅ‚adajÄ…cy siÄ™ z obrazÃ³w rentgenowskich klatki piersiowej do diagnozy zapalenia pÅ‚uc. GÅ‚Ã³wnym celem byÅ‚o zbudowanie, wytrenowanie i porÃ³wnanie dwÃ³ch architektur sieci neuronowych: w peÅ‚ni poÅ‚Ä…czonej sieci neuronowej (FCN) oraz konwolucyjnej sieci neuronowej (CNN). Projekt demonstruje proces przygotowania danych, treningu, oceny modeli oraz analizuje przewagi i ograniczenia kaÅ¼dej z architektur w kontekÅ›cie zadaÅ„ klasyfikacji obrazÃ³w.

## ğŸ“‚ Struktura Projektu

Projekt obejmuje analizÄ™ dwÃ³ch zbiorÃ³w danych przy uÅ¼yciu dwÃ³ch rÃ³Å¼nych architektur sieci neuronowych. Prace zostaÅ‚y zrealizowane w Å›rodowisku Google Colab.

## âš™ï¸ Metodologia

### 1. Wczytywanie i Przygotowanie Danych

NiezaleÅ¼nie dla obu zbiorÃ³w danych (MNIST i PneumoniaMNIST) przeprowadzono nastÄ™pujÄ…ce kroki:

* **ZbiÃ³r MNIST:**
    * Wczytanie danych (60 000 obrazÃ³w treningowych, 10 000 testowych, 28x28 pikseli, skala szaroÅ›ci) z biblioteki Keras.
    * PodziaÅ‚ zbioru treningowego na wÅ‚aÅ›ciwy zbiÃ³r treningowy (85%) i walidacyjny (15%).
    * Normalizacja wartoÅ›ci pikseli do zakresu [0, 1].
    * SpÅ‚aszczenie obrazÃ³w ($28 \times 28$ do wektorÃ³w 784) dla FCN.
    * Zachowanie struktury 2D (28, 28, 1) dla CNN.
    * Kodowanie "one-hot" etykiet (0-9).
* **ZbiÃ³r PneumoniaMNIST:**
    * Wczytanie danych (obrazy RTG klatki piersiowej, klasy: Normal vs. Pneumonia) przy uÅ¼yciu `tensorflow_datasets`.
    * Zmiana rozmiaru obrazÃ³w do $28 \times 28$ pikseli i konwersja do skali szaroÅ›ci.
    * Normalizacja wartoÅ›ci pikseli do zakresu [0, 1].
    * SpÅ‚aszczenie obrazÃ³w (28x28x1 do wektorÃ³w 784) dla FCN.
    * Zachowanie struktury 2D (28, 28, 1) dla CNN.
    * Kodowanie "one-hot" etykiet binarnych ([1, 0], [0, 1]).

### 2. Architektury Modeli

* **W PeÅ‚ni PoÅ‚Ä…czona SieÄ‡ Neuronowa (FCN):**
    * Warstwa wejÅ›ciowa (784 neurony).
    * Dwie ukryte warstwy gÄ™ste (Dense) po 512 neuronÃ³w z aktywacjÄ… ReLU i Dropout (0.2, 0.1/0.2).
    * Warstwa wyjÅ›ciowa Dense (10 neuronÃ³w dla MNIST, 2 dla PneumoniaMNIST) z aktywacjÄ… Softmax.
* **Konwolucyjna SieÄ‡ Neuronowa (CNN):**
    * Dwa bloki konwolucyjne (Conv2D 3x3 ReLU + MaxPooling 2x2; 32 filtry w bloku 1, 64 w bloku 2).
    * Dodatkowo Batch Normalization w modelu PneumoniaMNIST.
    * CzÄ™Å›Ä‡ FCN (Flatten, Dense 512 ReLU, Dropout 0.2, Dense wyjÅ›ciowe z Softmax).

### 3. Proces Treningu

* Kompilacja modeli z funkcjÄ… kosztu `categorical_crossentropy`, optymalizatorem `Adam` (lub `SGD` dla FCN MNIST) i metrykÄ… `accuracy`.
* Trening przez okreÅ›lonÄ… liczbÄ™ epok z ustalonym `batch_size`.
* Zastosowanie augmentacji danych dla CNN PneumoniaMNIST.
* Monitorowanie postÄ™pu za pomocÄ… `livelossplot`.

### 4. Ewaluacja Modeli

* Ocena wydajnoÅ›ci na zbiorach testowych.
* Wykorzystane metryki: dokÅ‚adnoÅ›Ä‡ (accuracy), strata (loss).
* Analiza macierzy pomyÅ‚ek i przykÅ‚adÃ³w bÅ‚Ä™dnych klasyfikacji.

## ğŸ› ï¸ Wykorzystane NarzÄ™dzia i Technologie

* **JÄ™zyk programowania:** Python
* **Biblioteki:**
    * TensorFlow z Keras API (budowa i trening modeli)
    * TensorFlow Datasets (wczytanie danych PneumoniaMNIST)
    * NumPy (operacje na danych)
    * Matplotlib i Seaborn (wizualizacja)
    * Scikit-learn (podziaÅ‚ danych, metryki)
    * Livelossplot (monitorowanie treningu)
* **Åšrodowisko:** Google Colab

## ğŸ“Š Wyniki i Interpretacja

### Klasyfikacja MNIST

* **Model FCN:**
    * DokÅ‚adnoÅ›Ä‡ na zbiorze testowym: 94.74%
    * Strata na zbiorze testowym: 0.1844
    * Poprawnie sklasyfikowano 9474 obrazy, bÅ‚Ä™dnie 526.
* **Model CNN:**
    * DokÅ‚adnoÅ›Ä‡ na zbiorze testowym: 99.23%
    * Strata na zbiorze testowym: 0.0225
    * Poprawnie sklasyfikowano 9923 cyfry, bÅ‚Ä™dnie 77.

### Klasyfikacja PneumoniaMNIST

* **Model FCN:**
    * DokÅ‚adnoÅ›Ä‡ na zbiorze testowym: 80.13%
    * Strata na zbiorze testowym: 0.8064
    * Poprawnie sklasyfikowano 500 obrazÃ³w, bÅ‚Ä™dnie 124.
* **Model CNN:**
    * DokÅ‚adnoÅ›Ä‡ na zbiorze testowym: 86.38%
    * Strata na zbiorze testowym: 0.4459
    * Poprawnie sklasyfikowano 539 przypadkÃ³w, mylÄ…c siÄ™ w 85.

### OgÃ³lna Interpretacja

Wyniki jednoznacznie potwierdzajÄ…, Å¼e architektury CNN sÄ… znacznie lepiej przystosowane do zadaÅ„ klasyfikacji obrazÃ³w niÅ¼ standardowe sieci FCN. Wykorzystanie cech przestrzennych przez warstwy konwolucyjne i pooling prowadzi do wyÅ¼szej dokÅ‚adnoÅ›ci, szczegÃ³lnie na bardziej zÅ‚oÅ¼onym zbiorze PneumoniaMNIST. Modele czÄ™sto mylÄ… klasy wizualnie podobne lub przypadki graniczne.

## ğŸ Podsumowanie i Wnioski

1.  **SkutecznoÅ›Ä‡ CNN:** Konwolucyjne sieci neuronowe wykazaÅ‚y znacznÄ… przewagÄ™ nad w peÅ‚ni poÅ‚Ä…czonymi sieciami w obu zadaniach klasyfikacji obrazÃ³w.
2.  **Znaczenie Przetwarzania Danych:** Odpowiednie przygotowanie danych (normalizacja, formatowanie, kodowanie etykiet) jest kluczowe dla sukcesu modeli. Augmentacja danych moÅ¼e poprawiÄ‡ generalizacjÄ™.
3.  **InterpretowalnoÅ›Ä‡ Modeli:** Analiza metryk, macierzy pomyÅ‚ek i przykÅ‚adÃ³w bÅ‚Ä™dÃ³w dostarcza cennych informacji o wydajnoÅ›ci i ograniczeniach modeli.
4.  **Praktyczne Zastosowanie NarzÄ™dzi:** Projekt zademonstrowaÅ‚ praktyczne wykorzystanie popularnych bibliotek do realizacji zadaÅ„ uczenia maszynowego.

## ğŸ’¡ Odpowiedzi na Kluczowe Pytania (FAQ)

* **Czym jest zbiÃ³r MNIST?** Standardowa baza danych rÄ™cznie pisanych cyfr (0-9), 28x28 pikseli, uÅ¼ywana do testowania algorytmÃ³w rozpoznawania obrazÃ³w.
* **Co to jest format One-Hot?** Metoda kodowania kategorii jako wektorÃ³w binarnych, gdzie tylko jedna pozycja ma wartoÅ›Ä‡ 1. Np. cyfra '3' to `[0,0,0,1,0,0,0,0,0,0]`.
* **KtÃ³ry neuron odpowiada za cyfrÄ™ '0' w modelu MNIST?** W 10-klasowym modelu z kodowaniem one-hot, neuron na pierwszej pozycji (indeks 0) odpowiada cyfrze '0'.
* **RÃ³Å¼nice miÄ™dzy funkcjami kosztu Categorical Cross-Entropy a Binary Cross-Entropy:** Categorical jest uÅ¼ywana dla wielu klas (>2) z etykietami one-hot. Binary jest dla dwÃ³ch klas, czÄ™sto z pojedynczym neuronem wyjÅ›ciowym (sigmoid).
* **WpÅ‚yw GPU na przyspieszenie treningu:** UÅ¼ycie GPU znaczÄ…co przyspiesza trening (zwÅ‚aszcza CNN), czÄ™sto kilkukrotnie lub kilkudziesiÄ™ciokrotnie w porÃ³wnaniu do CPU.
* **Czy sieci neuronowe popeÅ‚niajÄ… bÅ‚Ä™dy podobne do ludzkich?** Tak, sieci (szczegÃ³lnie FCN) mogÄ… myliÄ‡ wizualnie podobne cyfry (np. 1 i 7), co widaÄ‡ w macierzach pomyÅ‚ek.
* **WpÅ‚yw rozmiaru Batch Size na trening:**
    * **DuÅ¼y (np. 10000):** Skraca czas epoki, ale moÅ¼e pogorszyÄ‡ generalizacjÄ™.
    * **MaÅ‚y (np. 32):** WydÅ‚uÅ¼a czas epoki, ale czÄ™sto poprawia generalizacjÄ™.
* **PorÃ³wnanie FCN vs CNN dla rozpoznawania cyfr:** CNN sÄ… znacznie lepsze, poniewaÅ¼ wykorzystujÄ… informacje o przestrzennej strukturze pikseli.

---
